{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用Tensorflow构建VGG16模型实现猫狗识别\n",
    "\n",
    "图像识别技术可以识别出图像或者视频中的物体类别。本实验基于猫狗数据集，使用Keras手动搭建一个经典的VGG16卷积神经网络，训练一个猫狗分类模型。\n",
    "\n",
    "## 数据集\n",
    "\n",
    "猫狗识别数据集，猫和狗各12500张图片，图片名称中含有类别名称（cat和dog）。我们会根据图片名称中包含的类别名称（cat或dog）给图片打标签，狗的标签打成1，猫的标签打成0。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 依赖安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade keras_applications==1.0.6 keras==2.2.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入依赖库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2, random\n",
    "import numpy as np\n",
    "\n",
    "# 画图工具\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import Callback, EarlyStopping, TensorBoard\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last') # 数据格式data_format设置为 NHWC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下载数据集\n",
    "\n",
    "下载数据压缩包，解压，然后清理压缩包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://modelarts-labs-bj4.obs.cn-north-4.myhuaweicloud.com/notebook/DL_image_recognition/image_recognition.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('./data'):\n",
    "    !tar xf ./image_recognition.tar.gz\n",
    "    !rm -f ./image_recognition.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据集\n",
    "\n",
    "读取数据集，并把图像resize到 128 * 128 大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data/' # 数据集路径\n",
    "\n",
    "# 目标缩放尺寸\n",
    "ROWS = 128\n",
    "COLS = 128\n",
    "CHANNELS = 3\n",
    "\n",
    "image_file_names = [DATA_DIR+i for i in os.listdir(DATA_DIR)] \n",
    "dogs = [DATA_DIR+i for i in os.listdir(DATA_DIR) if 'dog' in i]\n",
    "cats = [DATA_DIR+i for i in os.listdir(DATA_DIR) if 'cat' in i]\n",
    "\n",
    "# 数据洗牌\n",
    "random.shuffle(image_file_names)\n",
    "\n",
    "def read_image(file_path):\n",
    "    img = cv2.imread(file_path, cv2.IMREAD_COLOR) # 彩色模式读取图像\n",
    "    return cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "def prep_data(image_file_names):\n",
    "    count = len(image_file_names)\n",
    "    data = np.ndarray((count, ROWS, COLS, CHANNELS), dtype=np.uint8)\n",
    "    \n",
    "    for i, image_file in enumerate(image_file_names):\n",
    "        image = read_image(image_file)\n",
    "        data[i] = image\n",
    "        if i%1000 == 0: print('Processed {} of {}'.format(i, count))\n",
    "    \n",
    "    return data\n",
    "\n",
    "# 读取图片至内存\n",
    "images = prep_data(image_file_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 给图片打标签\n",
    "\n",
    "我们根据图片名称包含的字符串给图片打标签。我们用0表示cat，1表示dog。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_samples = len(image_file_names)\n",
    "num_classes = 2 # 类别数是2\n",
    "labels = []\n",
    "\n",
    "index = 0\n",
    "for filename in image_file_names:\n",
    "    if 'dog' in filename:\n",
    "        labels.append(1)\n",
    "    elif 'cat' in filename:\n",
    "        labels.append(0)\n",
    "        \n",
    "# 把类别标签转换为onehot编码\n",
    "labels = np_utils.to_categorical(labels, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 切分数据集\n",
    "\n",
    "（train_data，train_label）是训练数据，（test_data，test_label）是测试数据。测试数据占25%。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_label, test_label = train_test_split(images, labels, test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看猫狗的样本图片\n",
    "\n",
    "这些图片是经过尺寸调整后的图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_cats_and_dogs(idx):\n",
    "    cat = read_image(cats[idx])\n",
    "    dog = read_image(dogs[idx])\n",
    "    pair = np.concatenate((cat, dog), axis=1)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.imshow(pair)\n",
    "    plt.show()\n",
    "    \n",
    "for idx in range(0,3):\n",
    "    show_cats_and_dogs(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建神经网络\n",
    "\n",
    "Keras是一个非常简单易用的，适合新手入门的深度学习引擎。接下来，我们使用Keras搭建一个VGG16卷积神经网络。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 设置超参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 # 批大小\n",
    "learning_rate = 1e-5 # 设置学习率为1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 设置优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=learning_rate) # 优化器使用 Adam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = 'categorical_crossentropy' # loss 函数使用交叉熵\n",
    "\n",
    "def load_model():\n",
    "    # 这是一个模型参数随机初始化的模型，如果想要加载imagenet预训练模型，可以设置 weights='imagenet'\n",
    "    base_model = VGG16(include_top=False, weights=None, input_shape=(ROWS, COLS, CHANNELS), pooling='avg')\n",
    "\n",
    "    x = base_model.output\n",
    "    \n",
    "    # 修改base_model的模型输出层。这是一个二分类的问题。\n",
    "    prediction_layer = Dense(2, activation='softmax')(x)\n",
    "    \n",
    "    # 组装成新的模型\n",
    "    model = Model(inputs=base_model.input, outputs=prediction_layer)\n",
    "    \n",
    "    # 模型编译\n",
    "    model.compile(loss=objective, optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型结构概览\n",
    "\n",
    "可以查看到刚刚搭建的神经网络结构的详情。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练\n",
    "\n",
    "在模型训练过程中，为了防止过拟合，我们使用了early stopping策略，当val_loss在连续3个epoch不再减少的情况下，就停止训练。\n",
    "\n",
    "本案例训练15轮，大概耗费10分钟。\n",
    "\n",
    "可以看到训练日志输出，其中会打印Loss（损失函数）和acc（精确度）信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15 # 训练轮数\n",
    "\n",
    "# early stopping策略\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')   \n",
    "\n",
    "def run_train():\n",
    "    \n",
    "    # 开始训练\n",
    "    history = model.fit(\n",
    "        train_data, \n",
    "        train_label, \n",
    "        batch_size=batch_size, \n",
    "        epochs=epochs,\n",
    "        validation_split=0.2,  # 训练数据中，抽取20%的数据作为验证数据\n",
    "        verbose=1,\n",
    "        shuffle=True,\n",
    "        callbacks=[early_stopping]) \n",
    "    return history\n",
    "\n",
    "history = run_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存模型\n",
    "\n",
    "训练好的模型可以保存起来，永久使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT = 'output'\n",
    "\n",
    "if not os.path.exists(OUTPUT):\n",
    "    os.mkdir(OUTPUT)\n",
    "\n",
    "model.save(os.path.join(OUTPUT, 'model.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可视化训练过程\n",
    "\n",
    "将Loss随epoch的变化趋势使用折线图展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('VGG-16 Loss Trend')\n",
    "plt.plot(loss, 'blue', label='Training Loss')\n",
    "plt.plot(val_loss, 'green', label='Validation Loss')\n",
    "plt.xticks(range(0, epochs)[0::2])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将accurary随epoch的变化趋势使用折线图展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('acc')\n",
    "plt.title('VGG-16 acc Trend')\n",
    "plt.plot(acc, 'blue', label='Training acc')\n",
    "plt.plot(val_acc, 'green', label='Validation acc')\n",
    "plt.xticks(range(0, epochs)[0::2])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 样本数据预测\n",
    "\n",
    "预测测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_data, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "直观展示10个样本数据的预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "    p = predictions[i]\n",
    "    \n",
    "    if round(p[1]) == 1: \n",
    "        print('I am {:.2%} sure this is a Dog'.format(p[1]))\n",
    "    else: \n",
    "        print('I am {:.2%} sure this is a Cat'.format(1 - p[1]))\n",
    "        \n",
    "    plt.imshow(test_data[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评估模型准确度\n",
    "\n",
    "通过测试集的预测结果，计算模型的准确度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test_array = []\n",
    "test_label_array = []\n",
    "\n",
    "# 将onehot编码的数据进行格式转换\n",
    "for p in predictions:\n",
    "    if round(p[1]) == 1:\n",
    "        predictions_test_array.append(1)\n",
    "    else:\n",
    "        predictions_test_array.append(0)\n",
    "        \n",
    "for t in test_label:\n",
    "    if int(t[1]) == 1:\n",
    "        test_label_array.append(1)\n",
    "    else:\n",
    "        test_label_array.append(0)\n",
    "        \n",
    "acc = accuracy_score(test_label_array, predictions_test_array)\n",
    "\n",
    "print('训练得到的猫狗识别模型的准确度是：%f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "本Notebook使用Keras搭建了一个VGG16神经网络，并使用猫狗数据集训练了一个猫狗识别模型。"
   ]
  }
 ],
 "metadata": {
  "imageInfo": {
   "id": "e1a07296-22a8-4f05-8bc8-e936c8e54090",
   "name": "notebook2.0-mul-kernel-cpu-cp36"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "shareInfo": {
   "id": "ae651308-2cfb-435f-83d3-bf9ec3a723bc",
   "url": "https://authoring-modelarts-cnnorth4.huaweicloud.com/console/lab?share-url-b64=aHR0cHM6Ly9ub3RlYm9va3NoYXJlLm9icy5jbi1ub3J0aC00Lm15aHVhd2VpY2xvdWQuY29tL2I4NjY3NWRmZTE5NzRjNTliOWM5NDA2ZWE1ZmViZDU4L3RlbnNvcmZsb3dfdmdnMTZfY2F0X2RvZ19yZWNvbmdpdGlvbl9ncHUuaXB5bmI%3D"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
